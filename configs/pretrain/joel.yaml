trinary_mz:
  test: 123

  # Training hparams
  batch_size: 100
  lr_warmup: 0
  lr_start: 1.0e-7
  lr_end: 2.0e-4
  lr_warmup_steps: 20000
  blr: 4.0e-5
  lr_decay: False
  weight_decay: 1.0e-5
  epochs: 1
  subset: 0
  num_workers: 0
  dropout: 0

masked:
  # Masked trainer specific hparams
  predict_fourier: True
  mask_token_fourier: True
  learned_masked_token: True
  positional_encoding: True
  mz_to_int_ratio: 0.67
  mask_ratio: 0.75
  
  # Training hparams
  batch_size: 100
  blr: 4.0e-5
  weight_decay: 1.0e-5
  epochs: 1
  subset: 0
  num_workers: 0
  dropout: 0

  # Annealing
  lr_warmup: 1
  lr_start: 1.0e-7
  lr_end: 2.0e-4
  lr_warmup_steps: 20000
  lr_decay: 0

masked_ae:
  # Masked Autoencoder trainer specific hparams
  predict_fourier: True
  mask_token_fourier: True
  learned_masked_token: True
  positional_encoding: True
  mz_to_int_ratio: 0.67
  mask_ratio: 0.75

  # Decoder architecture hparams
  decoder_running_units: 256
  decoder_nhead: 8
  decoder_dim_feedforward: 1024
  decoder_dropout: 0
  decoder_nlayers: 6

  # Training hparams
  batch_size: 100
  blr: 4.0e-5
  weight_decay: 1.0e-5
  epochs: 1
  subset: 0
  num_workers: 0
  dropout: 0

  # Annealing
  lr_warmup: 1
  lr_start: 1.0e-7
  lr_end: 2.0e-4
  lr_warmup_steps: 20000
  lr_decay: 0
